---
title: Blue-Green Zero-Downtime Deployment with Docker and Nginx
description: How to achieve zero-downtime deployment using a Blue-Green strategy with Docker
thumbnail: /thumbnails/bluegreen-ori.gif
date: "Jan 12, 2026"
---

## Implementing Blue-Green Zero-Downtime Deployment with Nginx and Docker

<br />

It feels like I only ever write about deployment these days. Haha, but I love it! The company is growing steadily, so lately, I‚Äôve been busy modernizing our legacy sites. Plus, since we‚Äôve actively embraced "Vibe Coding" (relying on AI/LLMs), I rarely have to write boilerplate code from scratch anymore. Naturally, this has freed up my time to dive deeper into automation and DevOps.

<br />
For this latest renewal project, I decided to deploy by spinning up Docker images on the server. Previously, we handled everything by serving static files via PM2 and Nginx. I decided to move away from that and adopt Docker for two main reasons:

<br />
<ol>
  <li>1. Environment Consistency: The project uses Next.js API Routes, which require a server runtime. I needed to set up an independent executable server using output: standalone mode in next.config. However, the Node.js version on the server was different from what the project required. Docker allowed me to isolate the environment perfectly.</li>
  <li>2. CI/CD Readiness: To make future CI/CD integrations much smoother.</li>
</ol>

<br />

Initially, I just did a basic Docker build and deploy. Since the site wasn't public yet, I didn't worry about downtime. But that meant anyone trying to access the site during a build would hit a 502 Bad Gateway error. üòÖ Since we‚Äôre about to go live, it was time to implement a proper zero-downtime deployment strategy.

<br />
<div className="bar" />

## What is Blue-Green Deployment?
The concept is actually quite simple.

<MDXImage
  src="/posts/blue-green/diagram.png"
  alt="blue-green diagram"
  style={{ width: "70%" }}
/>

Blue and Green take turns being the "Active" (production) and "Update" (idle) environments.
<br />
When it‚Äôs time to update the site, if Green is currently live, Blue starts the build process. Once Blue is finished building and passes health checks, Nginx switches traffic to Blue. Green then goes into standby mode. By toggling roles like this, the service never goes down.
<br />
Here is how the flow looks inside the server:

<CodeBlock>
```
1. Pull the latest code via Git.
2. Run deploy.sh.
3. Build the idle container (e.g., Green).
4. Run a health check on the new container.
5. Update Nginx configuration (Blue ‚Üí Green).
6. Reload Nginx.
7. Switch the old container (Blue) to standby.

```
</CodeBlock>

Note: Since you're running two containers (Blue and Green), memory usage doubles. Keep this in mind if you're working on a small-scale server.
<br />

### Creating the Docker-compose Files
I split the configuration into docker-compose.blue.yml and docker-compose.green.yml. Since the original site was on port 3080, I assigned ports 3080 and 3081. The Green config follows the same logic as the Blue one below. 

<CodeBlock>
```

// docker-compose.blue.yml

services:
  barista-blue:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_BASE_URL=https://api.example.com  # Manage actual env vars via .env file
        - NEXT_PUBLIC_MONITOR_API_URL=https://example.com
        - NEXT_PUBLIC_MEGA_API_URL=https://api.example.com
        - NEXT_PUBLIC_BARISTA_MONITOR_URL=https://example.com
    container_name: barista-blue
    restart: unless-stopped
    ports:
      - "3080:3000"
    environment:
      - NODE_ENV=production
    networks:
      - ~-network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

networks:
  ~-network:
    driver: bridge

```
</CodeBlock>

### Updating the Dockerfile

<CodeBlock>
```
# Stage 1: Dependencies
FROM node:20-alpine AS deps
RUN apk add --no-cache libc6-compat
WORKDIR /app

# Install bun for faster package installation
RUN npm install -g bun

# Copy package files
COPY package.json bun.lock* ./

# Install dependencies
RUN bun install --frozen-lockfile

# ================================
# Stage 2: Builder
# ================================
FROM node:20-alpine AS builder
WORKDIR /app

# Copy dependencies from deps stage
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# Build arguments for environment variables
ARG NEXT_PUBLIC_API_BASE_URL
ARG NEXT_PUBLIC_MONITOR_API_URL
ARG NEXT_PUBLIC_MEGA_API_URL
ARG NEXT_PUBLIC_BARISTA_MONITOR_URL

# Set environment variables for build
ENV NEXT_PUBLIC_API_BASE_URL=$NEXT_PUBLIC_API_BASE_URL
ENV NEXT_PUBLIC_MONITOR_API_URL=$NEXT_PUBLIC_MONITOR_API_URL
ENV NEXT_PUBLIC_MEGA_API_URL=$NEXT_PUBLIC_MEGA_API_URL
ENV NEXT_PUBLIC_BARISTA_MONITOR_URL=$NEXT_PUBLIC_BARISTA_MONITOR_URL

# Build the application
RUN npm run build

# ================================
# Stage 3: Runner (Production)
# ================================
FROM node:20-alpine AS runner
WORKDIR /app

ENV NODE_ENV=production

# Create non-root user for security
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

# Copy necessary files from builder
COPY --from=builder /app/public ./public
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static

# Set correct permissions
RUN chown -R nextjs:nodejs /app

USER nextjs

EXPOSE 3000

ENV PORT=3000
ENV HOSTNAME="0.0.0.0"

CMD ["node", "server.js"]
```
</CodeBlock>

Even after building the Docker image, how does Nginx know to swap the two containers? We need an executable script to handle the "switch."

### Creating the deploy.sh Script

<CodeBlock>
```
// deploy.sh

set -e  # Stop script on error

# ================================
# Configuration
# ================================
PROJECT_DIR="$(cd "$(dirname "$0")" && pwd)"
NGINX_BIN="~/nginx"  # Path to nginx binary on server
NGINX_CONF="~/nginx.conf"  # Path to nginx.conf file on server
HEALTH_CHECK_URL_BLUE="http://localhost:3080"
HEALTH_CHECK_URL_GREEN="http://localhost:3081"
HEALTH_CHECK_RETRIES=30
HEALTH_CHECK_INTERVAL=2

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ================================
# Functions
# ================================

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Check active environment based on nginx config
get_active_env() {
    if grep -q "server localhost:3080;" "$NGINX_CONF" 2>/dev/null && \
       ! grep -q "#.*server localhost:3080;" "$NGINX_CONF" 2>/dev/null; then
        echo "blue"
    elif grep -q "server localhost:3081;" "$NGINX_CONF" 2>/dev/null && \
         ! grep -q "#.*server localhost:3081;" "$NGINX_CONF" 2>/dev/null; then
        echo "green"
    else
        echo "blue"  # Default
    fi
}

# Health check function
health_check() {
    local url=$1
    local retries=$HEALTH_CHECK_RETRIES

    log_info "Starting health check: $url"

    while [ $retries -gt 0 ]; do
        if curl -sf "$url" > /dev/null 2>&1; then
            log_success "Health check passed!"
            return 0
        fi

        retries=$((retries - 1))
        log_info "Waiting for health check... ($retries attempts left)"
        sleep $HEALTH_CHECK_INTERVAL
    done

    log_error "Health check failed!"
    return 1
}

# Switch Nginx traffic
switch_nginx() {
    local target_env=$1

    log_info "Switching Nginx traffic to $target_env..."

    if [ "$target_env" == "blue" ]; then
        # Switch to Blue: enable 3080, comment out 3081
        sudo sed -i 's/#.*server localhost:3080;/server localhost:3080;/' "$NGINX_CONF"
        sudo sed -i 's/^\([^#]*\)server localhost:3081;/# server localhost:3081;/' "$NGINX_CONF"
    else
        # Switch to Green: enable 3081, comment out 3080
        sudo sed -i 's/#.*server localhost:3081;/server localhost:3081;/' "$NGINX_CONF"
        sudo sed -i 's/^\([^#]*\)server localhost:3080;/# server localhost:3080;/' "$NGINX_CONF"
    fi

    # Test Nginx configuration
    if sudo $NGINX_BIN -t; then
        sudo $NGINX_BIN -s reload
        log_success "Nginx traffic successfully switched!"
    else
        log_error "Nginx configuration error!"
        return 1
    fi
}

# ================================
# Main Deployment Logic
# ================================

main() {
    log_info "=========================================="
    log_info "Starting Blue-Green Deployment"
    log_info "=========================================="

    cd "$PROJECT_DIR"

    # Check current active environment
    CURRENT_ENV=$(get_active_env)

    if [ "$CURRENT_ENV" == "blue" ]; then
        TARGET_ENV="green"
        TARGET_COMPOSE="docker-compose.green.yml"
        TARGET_HEALTH_URL=$HEALTH_CHECK_URL_GREEN
        OLD_COMPOSE="docker-compose.blue.yml"
    else
        TARGET_ENV="blue"
        TARGET_COMPOSE="docker-compose.blue.yml"
        TARGET_HEALTH_URL=$HEALTH_CHECK_URL_BLUE
        OLD_COMPOSE="docker-compose.green.yml"
    fi

    log_info "Current Active Env: $CURRENT_ENV"
    log_info "Target Deployment Env: $TARGET_ENV"

    # 1. Deploy to new environment
    log_info "[$TARGET_ENV] Building and deploying new version..."
    docker compose -f "$TARGET_COMPOSE" up -d --build

    # 2. Health check
    log_info "[$TARGET_ENV] Performing health check..."
    if ! health_check "$TARGET_HEALTH_URL"; then
        log_error "Deployment failed! The $TARGET_ENV environment did not start properly."
        log_warning "Rolling back: Stopping $TARGET_ENV container."
        docker compose -f "$TARGET_COMPOSE" down
        exit 1
    fi

    # 3. Switch Nginx traffic
    switch_nginx "$TARGET_ENV"

    log_success "=========================================="
    log_success "Deployment Complete!"
    log_success "Active Env: $TARGET_ENV"
    log_success "=========================================="

    # Display status
    echo ""
    log_info "Current Container Status:"
    docker ps --filter "name=~-barista" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
}

# Execute script
main "$@"
```
</CodeBlock>

Of course, you'll also need to update your `nginx.conf` file on the server. I added the following `upstream` block to the renewal page section of the existing config file.

<CodeBlock>
```
upstream barista_backend { 
    # üëÜ The 'upstream' block defines the backend servers for load balancing/proxying in Nginx.
    # Currently active environment (blue or green)
    server localhost:3080;  # blue (default)
    # server localhost:3081;  # green
}
...
```
</CodeBlock>


To run it, pull the code on your server (make sure deploy.sh is in the project root directory) and run:

<CodeBlock>./deploy.sh</CodeBlock>

The script will perform a health check, and if it passes, it will modify the nginx.conf file, reload Nginx, and switch the traffic. If any step fails, the original server will continue serving so users aren't affected.

The first time you run it, you might get this error:

<CodeBlock>
  -bash: ./deploy.sh: Permission denied
</CodeBlock>

This means the file doesn't have execution permissions. Just grant it execution permissions:

<CodeBlock>
  chmod +x deploy.sh
</CodeBlock>

Then run ./deploy.sh again.

<MDXImage
  src="/posts/blue-green/success.png"
  alt="Successfully completed blue-green deployment"
  style={{ width: "70%" }}
/>
<br />
And there you have it‚Äîzero-downtime deployment successfully implemented! üòé‚úåÔ∏è‚úåÔ∏è
<br />
<br />